"""
PDF ë‹¤ìš´ë¡œë“œ ì§€ì› + í–¥ìƒëœ AI ë¶„ì„ ì—”ì§„
"""

import google.generativeai as genai
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
from reportlab.lib.pagesizes import A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
import io

class AdvancedPatentAnalyzer:
    """ê³ ë„í™”ëœ íŠ¹í—ˆ ë¶„ì„ + PDF ìƒì„± í´ë˜ìŠ¤"""
    
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.model_pro = genai.GenerativeModel('gemini-2.0-flash-exp')
        self.model_flash = genai.GenerativeModel('gemini-1.5-flash')
    
    def quick_summarize(self, text: str) -> str:
        """ë¹ ë¥¸ ìš”ì•½ - Flash ëª¨ë¸ ì‚¬ìš©"""
        try:
            prompt = f"""ë‹¤ìŒ íŠ¹í—ˆ ì´ˆë¡ì„ ì „ë¬¸ê°€ ìˆ˜ì¤€ìœ¼ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”.

ì´ˆë¡: {text[:1000]}

ìš”ì•½ ê¸°ì¤€:
- í•µì‹¬ ê¸°ìˆ  ë‚´ìš©
- ì£¼ìš” íŠ¹ì§• ë° ì¥ì   
- ì‘ìš© ë¶„ì•¼
- 3-4ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬"""

            response = self.model_flash.generate_content(prompt)
            return response.text
        except Exception as e:
            return f"ìš”ì•½ ì˜¤ë¥˜: {e}"
    
    def comprehensive_analysis(self, patents: List[Dict], analysis_type: str, user_query: str = "") -> str:
        """ì¢…í•© íŠ¹í—ˆ ë¶„ì„ - ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìµœì í™”"""
        try:
            print(f"ğŸ§  AI ë¶„ì„ ì‹œì‘: {len(patents)}ê±´ íŠ¹í—ˆ ë¶„ì„ ì¤‘...")
            
            # ë°ì´í„° ì „ì²˜ë¦¬ ë° í†µê³„ ìƒì„±
            analysis_data = self._prepare_comprehensive_data(patents)
            
            # ë¶„ì„ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._generate_expert_prompt(analysis_data, analysis_type, user_query)
            
            response = self.model_pro.generate_content(prompt)
            return response.text
            
        except Exception as e:
            return f"ë¶„ì„ ì˜¤ë¥˜: {e}"
    
    def generate_pdf_report(self, analysis_data: Dict, analysis_result: str) -> io.BytesIO:
        """ì „ë¬¸ì ì¸ PDF ë³´ê³ ì„œ ìƒì„±"""
        buffer = io.BytesIO()
        
        doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=72, leftMargin=72, topMargin=72, bottomMargin=18)
        
        styles = getSampleStyleSheet()
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • ì‹œë„
        try:
            pdfmetrics.registerFont(TTFont('MalgunGothic', 'C:/Windows/Fonts/malgun.ttf'))
            title_style = ParagraphStyle('CustomTitle', parent=styles['Heading1'], fontName='MalgunGothic')
            header_style = ParagraphStyle('CustomHeader', parent=styles['Heading2'], fontName='MalgunGothic')
            normal_style = ParagraphStyle('CustomNormal', parent=styles['Normal'], fontName='MalgunGothic')
        except:
            title_style = styles['Title']
            header_style = styles['Heading2']
            normal_style = styles['Normal']
        
        # ë¬¸ì„œ ë‚´ìš© êµ¬ì„±
        story = []
        
        # ì œëª©
        story.append(Paragraph("ğŸ¤– AI íŠ¹í—ˆ ë¶„ì„ ë³´ê³ ì„œ", title_style))
        story.append(Spacer(1, 12))
        
        # ê¸°ë³¸ ì •ë³´
        story.append(Paragraph("ğŸ“‹ ë¶„ì„ ê°œìš”", header_style))
        story.append(Paragraph(f"ê²€ìƒ‰ì–´: {analysis_data.get('search_query', 'N/A')}", normal_style))
        story.append(Paragraph(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %Hì‹œ %Më¶„')}", normal_style))
        story.append(Paragraph(f"ì´ íŠ¹í—ˆ ìˆ˜: {analysis_data.get('total_count', 0):,}ê±´", normal_style))
        story.append(Spacer(1, 12))
        
        # ì£¼ìš” í†µê³„
        story.append(Paragraph("ğŸ“Š ì£¼ìš” í†µê³„", header_style))
        
        # ì¶œì›ì¸ TOP 5
        top_applicants = analysis_data.get('top_applicants', {})
        if top_applicants:
            story.append(Paragraph("ì£¼ìš” ì¶œì›ì¸:", normal_style))
            for i, (name, count) in enumerate(list(top_applicants.items())[:5], 1):
                story.append(Paragraph(f"{i}. {name}: {count}ê±´", normal_style))
            story.append(Spacer(1, 12))
        
        # ì—°ë„ë³„ ë™í–¥
        yearly_data = analysis_data.get('yearly_trends', {})
        if yearly_data:
            story.append(Paragraph("ì—°ë„ë³„ ì¶œì› í˜„í™©:", normal_style))
            for year, count in yearly_data.items():
                story.append(Paragraph(f"â€¢ {year}ë…„: {count}ê±´", normal_style))
            story.append(Spacer(1, 12))
        
        # AI ë¶„ì„ ê²°ê³¼
        story.append(PageBreak())
        story.append(Paragraph("ğŸ§  AI ë¶„ì„ ê²°ê³¼", header_style))
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ë‹¨ë³„ë¡œ ë‚˜ëˆ„ì–´ ì¶”ê°€
        analysis_paragraphs = analysis_result.split('\n\n')
        for para in analysis_paragraphs:
            if para.strip():
                cleaned_para = para.replace('**', '').replace('##', '').replace('#', '').strip()
                if cleaned_para:
                    story.append(Paragraph(cleaned_para, normal_style))
                    story.append(Spacer(1, 6))
        
        doc.build(story)
        buffer.seek(0)
        return buffer
    
    def _prepare_comprehensive_data(self, patents: List[Dict]) -> Dict:
        """ëŒ€ëŸ‰ íŠ¹í—ˆ ë°ì´í„° ì¢…í•© ë¶„ì„ìš© ì „ì²˜ë¦¬"""
        applicants = {}
        years = {}
        statuses = {}
        ipc_codes = {}
        
        for patent in patents:
            # ì¶œì›ì¸ í†µê³„
            applicant = patent.get('applicant', 'ì •ë³´ì—†ìŒ')[:50]
            applicants[applicant] = applicants.get(applicant, 0) + 1
            
            # ì—°ë„ë³„ í†µê³„
            app_date = patent.get('app_date', '')
            if app_date and len(app_date) >= 4:
                year = app_date[:4]
                years[year] = years.get(year, 0) + 1
            
            # ë“±ë¡ìƒíƒœ í†µê³„
            status = patent.get('reg_status', 'ì¶œì›')
            statuses[status] = statuses.get(status, 0) + 1
            
            # IPC ì½”ë“œ ë¶„ì„
            ipc = patent.get('ipc_code', '')
            if ipc:
                ipc_main = ipc.split()[0][:4] if ipc.split() else ipc[:4]
                ipc_codes[ipc_main] = ipc_codes.get(ipc_main, 0) + 1
        
        return {
            'total_count': len(patents),
            'top_applicants': dict(sorted(applicants.items(), key=lambda x: x[1], reverse=True)[:15]),
            'yearly_trends': dict(sorted(years.items())),
            'status_distribution': statuses,
            'ipc_distribution': dict(sorted(ipc_codes.items(), key=lambda x: x[1], reverse=True)[:10]),
            'patents_sample': patents[:3]
        }
    
    def _generate_expert_prompt(self, data: Dict, analysis_type: str, user_query: str) -> str:
        """ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_context = f"""# íŠ¹í—ˆ ë¹…ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œ

## ğŸ“Š ë¶„ì„ ë°ì´í„° ê·œëª¨
- **ì´ ë¶„ì„ íŠ¹í—ˆ**: {data['total_count']:,}ê±´
- **ë¶„ì„ ì™„ë£Œ ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M')}
- **ì£¼ìš” ê¸°ìˆ  ë¶„ì•¼**: {len(data.get('ipc_distribution', {}))}ê°œ IPC ì½”ë“œ

## ğŸ¢ ì‹œì¥ ì°¸ì—¬ì í˜„í™©
{self._format_market_analysis(data)}

## ğŸ“ˆ ê¸°ìˆ  ë°œì „ íŠ¸ë Œë“œ  
{self._format_trend_analysis(data)}

## âš–ï¸ íŠ¹í—ˆ ê¶Œë¦¬ í˜„í™©
{self._format_rights_analysis(data)}
"""

        expert_prompts = {
            "competitive_analysis": f"""{base_context}

## ğŸ† ì‹¬í™” ê²½ìŸ ë¶„ì„ ìš”ì²­

ìœ„ ëŒ€ê·œëª¨ íŠ¹í—ˆ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ ê´€ì ì—ì„œ **ì „ëµì»¨ì„¤íŒ… ìˆ˜ì¤€**ì˜ ê²½ìŸ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”:

### 1. ì‹œì¥ ì§€ë°°ë ¥ êµ¬ì¡° ë¶„ì„
- íŠ¹í—ˆ í¬íŠ¸í´ë¦¬ì˜¤ ê·œëª¨ë³„ ê¸°ì—… ê³„ì¸µí™”
- ê¸°ìˆ  ì˜í–¥ë ¥ ì§€ìˆ˜ ë° í•µì‹¬ í”Œë ˆì´ì–´ ì‹ë³„
- ì‹œì¥ ì§„ì… ì¥ë²½ ë° ê¸°ìˆ ì  í•´ì ë¶„ì„

### 2. ê¸°ìˆ  ê²½ìŸ ì¸í…ì‹œí‹° ë§µí•‘
- IPC ì½”ë“œë³„ ê²½ìŸ ë°€ë„ ë° í˜ì‹  í™œë°œë„
- íŠ¹í—ˆ ë¶„ìŸ ë¦¬ìŠ¤í¬ê°€ ë†’ì€ í•«ì¡´ ì‹ë³„
- ê¸°ìˆ  ìœµí•© ë° ê²½ê³„ í™•ì¥ íŒ¨í„´

### 3. ì „ëµì  í¬ì§€ì…”ë‹ ì¸ì‚¬ì´íŠ¸
- ê° ì£¼ìš” ê¸°ì—…ì˜ ê¸°ìˆ  ì „ëµ ë°©í–¥ì„±
- í˜‘ë ¥ vs ê²½ìŸ êµ¬ë„ ë° ì—ì½”ì‹œìŠ¤í…œ ë¶„ì„
- M&A ë° ë¼ì´ì„ ì‹± ê¸°íšŒ ì˜ì—­

**ğŸ¯ ìµœì¢… ê²°ê³¼ë¬¼**: C-Level ê²½ì˜ì§„ ëŒ€ìƒ ì „ëµ ì˜ì‚¬ê²°ì •ìš© í•µì‹¬ ì¸ì‚¬ì´íŠ¸""",

            "trend_analysis": f"""{base_context}

## ğŸ“ˆ ê¸°ìˆ  íŠ¸ë Œë“œ ì˜ˆì¸¡ ë¶„ì„

### 1. ê¸°ìˆ  ë¼ì´í”„ì‚¬ì´í´ ë¶„ì„
- í˜„ì¬ ê¸°ìˆ  ì„±ìˆ™ë„ ë° S-Curve ìƒì˜ ìœ„ì¹˜
- ì‹ ê¸°ìˆ  ë„ì…ê¸° vs ì„±ìˆ™ê¸° ê¸°ìˆ  êµ¬ë¶„
- ì°¨ì„¸ëŒ€ ê¸°ìˆ ë¡œì˜ ì „í™˜ ì‹œì  ì˜ˆì¸¡

### 2. í˜ì‹  íŒ¨í„´ ë° ë™ë ¥ ë¶„ì„
- ê¸°ìˆ  í˜ì‹ ì˜ ì£¼ìš” ë™ë ¥ì› (ì •ì±…, ì‹œì¥, ê¸°ìˆ )
- íŒŒê´´ì  í˜ì‹  vs ì ì§„ì  í˜ì‹  íŒ¨í„´
- ê¸€ë¡œë²Œ ê¸°ìˆ  íŠ¸ë Œë“œì™€ì˜ ì—°ê´€ì„±

### 3. ë¯¸ë˜ ê¸°ìˆ  ë°œì „ ë¡œë“œë§µ
- 5ë…„ í›„ ê¸°ìˆ  ì§€í˜• ì˜ˆì¸¡
- ìƒˆë¡œìš´ ê¸°íšŒ ì˜ì—­ ë° ì„±ì¥ ë™ë ¥
- ê¸°ìˆ  ìˆ˜ë ´ ë° ìœµí•© íŠ¸ë Œë“œ""",

            "future_direction": f"""{base_context}

## ğŸ”® ë¯¸ë˜ ë°©í–¥ì„± ë° ì „ëµ ì œì•ˆ

### 1. ê¸°ìˆ  ê¸°íšŒ ë°œêµ´ ë° ìš°ì„ ìˆœìœ„í™”
- íŠ¹í—ˆ ê³µë°±ì§€ëŒ€ ë° ë¸”ë£¨ì˜¤ì…˜ ì˜ì—­
- íˆ¬ì ëŒ€ë¹„ íš¨ê³¼ê°€ ë†’ì€ ê¸°ìˆ  ì˜ì—­
- ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ê¸°íšŒ ë§¤íŠ¸ë¦­ìŠ¤

### 2. íŠ¹í—ˆ ì „ëµ ë¡œë“œë§µ ìˆ˜ë¦½
- ë°©ì–´ì  vs ê³µê²©ì  íŠ¹í—ˆ ì „ëµ ê· í˜•
- í•µì‹¬ ì›ì²œê¸°ìˆ  vs ì‘ìš©ê¸°ìˆ  í¬íŠ¸í´ë¦¬ì˜¤
- ê¸€ë¡œë²Œ ì¶œì› ì „ëµ ë° ì§€ì—­ë³„ ìš°ì„ ìˆœìœ„

### 3. ì‹¤í–‰ ê³„íš ë° ìì› ë°°ë¶„
- íŠ¹í—ˆ í™•ë³´ë¥¼ ìœ„í•œ íˆ¬ì ìš°ì„ ìˆœìœ„
- ë‚´ë¶€ R&D vs ì™¸ë¶€ í˜‘ë ¥ ì „ëµ
- ìœ„í—˜ ê´€ë¦¬ ë° ì»¨í‹´ì „ì‹œ í”Œëœ"""
        }

        prompt = expert_prompts.get(analysis_type, expert_prompts["competitive_analysis"])
        
        if user_query:
            prompt += f"\n\n## ğŸ” ì¶”ê°€ ë¶„ì„ ìš”ì²­\n{user_query}\n\n**ì´ ì§ˆë¬¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ ìœ„ ë¶„ì„ì„ ë”ìš± êµ¬ì²´í™”í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œì‹œí•˜ì„¸ìš”.**"
        
        prompt += "\n\n**ğŸ“‹ ë³´ê³ ì„œ ì‘ì„± ê¸°ì¤€**: ê° ì„¹ì…˜ë³„ ëª…í™•í•œ ì œëª©, í•µì‹¬ í¬ì¸íŠ¸ëŠ” êµµì€ ê¸€ì”¨, ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆ, ì˜ì‚¬ê²°ì • ì§€ì›ìš© ëª…í™•í•œ ê²°ë¡ "
        
        return prompt
    
    def _format_market_analysis(self, data: Dict) -> str:
        """ì‹œì¥ ì°¸ì—¬ì í˜„í™© í¬ë§¤íŒ…"""
        lines = []
        for i, (name, count) in enumerate(list(data['top_applicants'].items())[:5], 1):
            percentage = (count / data['total_count']) * 100
            lines.append(f"{i}. **{name}**: {count:,}ê±´ ({percentage:.1f}%)")
        return "\n".join(lines)
    
    def _format_trend_analysis(self, data: Dict) -> str:
        """ê¸°ìˆ  ë°œì „ íŠ¸ë Œë“œ í¬ë§¤íŒ…"""
        yearly = data['yearly_trends']
        if len(yearly) < 2:
            return "â€¢ ì—°ë„ë³„ ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ ì œí•œ"
        
        years = list(yearly.keys())
        recent_year = years[-1]
        prev_year = years[-2] if len(years) > 1 else years[-1]
        
        recent_count = yearly[recent_year]
        prev_count = yearly[prev_year]
        
        if prev_count > 0:
            growth_rate = ((recent_count - prev_count) / prev_count) * 100
            trend = "ì¦ê°€" if growth_rate > 0 else "ê°ì†Œ"
            lines = [
                f"â€¢ **ìµœê·¼ ì¶œì› ë™í–¥**: {recent_year}ë…„ {recent_count:,}ê±´",
                f"â€¢ **ì „ë…„ ëŒ€ë¹„**: {abs(growth_rate):.1f}% {trend}",
                f"â€¢ **í™œë°œ ê¸°ê°„**: {min(yearly.keys())}ë…„~{max(yearly.keys())}ë…„"
            ]
        else:
            lines = [f"â€¢ **ìµœê·¼ ì¶œì›**: {recent_year}ë…„ {recent_count:,}ê±´"]
        
        return "\n".join(lines)
    
    def _format_rights_analysis(self, data: Dict) -> str:
        """ê¶Œë¦¬ í˜„í™© í¬ë§¤íŒ…"""
        statuses = data['status_distribution']
        total = sum(statuses.values())
        
        lines = []
        for status, count in statuses.items():
            percentage = (count / total) * 100 if total > 0 else 0
            lines.append(f"â€¢ **{status}**: {count:,}ê±´ ({percentage:.1f}%)")
        
        return "\n".join(lines)

# í˜¸í™˜ì„± í•¨ìˆ˜ë“¤
def summarize_text_with_gemini(api_key: str, text: str) -> str:
    analyzer = AdvancedPatentAnalyzer(api_key)
    return analyzer.quick_summarize(text)

def analyze_patent_data_with_gemini(api_key: str, patent_data: List[Dict], user_query: str) -> str:
    analyzer = AdvancedPatentAnalyzer(api_key)
    return analyzer.comprehensive_analysis(patent_data, "competitive_analysis", user_query)

def analyze_detailed_data_with_gemini(api_key: str, patent_data: List[Dict], user_query: str) -> str:
    analyzer = AdvancedPatentAnalyzer(api_key)
    return analyzer.comprehensive_analysis(patent_data, "future_direction", user_query)
